{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "67c260d0",
   "metadata": {},
   "source": [
    "Analysis of the impact of samplesize for exploratory landscape analysis features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a11536b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cocoex\n",
    "from pflacco.classical_ela_features import *\n",
    "from pflacco.sampling import create_initial_sample\n",
    "\n",
    "_features = []\n",
    "# Get all 24 single-objective noiseless BBOB function in dimension 2 and 3 for the first five instances.\n",
    "suite = cocoex.Suite(\"bbob\", f\"instances:1-5\", f\"function_indices:1-24 dimensions:2,3,5\")\n",
    "for problem in suite:\n",
    "    dim = problem.dimension\n",
    "    fid = problem.id_function\n",
    "    iid = problem.id_instance\n",
    "    #for sample_coefficient in [1, 50]:\n",
    "    for n in [10,20,50]:\n",
    "        #for i in range(100):\n",
    "            \n",
    "\n",
    "        # Create sample\n",
    "        #X = create_initial_sample(dim, lower_bound = -5, upper_bound = 5, sample_coefficient=sample_coefficient, sample_type='lhs')\n",
    "        X = create_initial_sample(dim, lower_bound = -5, upper_bound = 5, n=n, sample_type='lhs')\n",
    "        y = X.apply(lambda x: problem(x), axis = 1)\n",
    "\n",
    "        # Calculate ELA features\n",
    "        ela_meta = calculate_ela_meta(X, y)\n",
    "        ela_distr = calculate_ela_distribution(X, y)\n",
    "        fast_k = max(math.ceil(0.05 * X.shape[0]),2)\n",
    "        nbc = calculate_nbc(X, y, fast_k=fast_k)\n",
    "        disp = calculate_dispersion(X, y)\n",
    "        ic = calculate_information_content(X, y, seed = 100)\n",
    "        pca = calculate_pca(X, y)\n",
    "        #try:\n",
    "        #    level = calculate_ela_level(X, y)\n",
    "        #except Exception:\n",
    "        #    level = {}\n",
    "\n",
    "        # Store results in pandas dataframe ### **{'sample_coefficient': sample_coefficient}\n",
    "        data = pd.DataFrame({**ic, **ela_meta, **ela_distr, **nbc, **disp, **pca, **{'fid': fid}, **{'dim': dim}, **{'iid': iid}, **{'n': n}}, index = [0])\n",
    "        _features.append(data)\n",
    "        \n",
    "\n",
    "features_test = pd.concat(_features).reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1673442b",
   "metadata": {},
   "outputs": [],
   "source": [
    "features.to_parquet('df.lhs.gzip', compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88b04f9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cocoex\n",
    "from pflacco.classical_ela_features import *\n",
    "from pflacco.sampling import create_initial_sample\n",
    "features = pd.read_parquet('df.lhs.gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b049e946",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import minimize\n",
    "import cma\n",
    "\n",
    "import cocoex\n",
    "from pflacco.classical_ela_features import *\n",
    "from pflacco.sampling import create_initial_sample\n",
    "\n",
    "optimizers = ['BFGS', 'L-BFGS-B', 'SLSQP', cma.CMAEvolutionStrategy]\n",
    "func_evals = []\n",
    "# Get all 24 single-objective noiseless BBOB function in dimension 2 and 3 for the first five instances.\n",
    "suite = cocoex.Suite(\"bbob\", f\"instances:1-5\", f\"function_indices:1-24 dimensions:2,3,5,10\")\n",
    "for problem in suite:\n",
    "    dim = problem.dimension\n",
    "    fid = problem.id_function\n",
    "    iid = problem.id_instance\n",
    "    \n",
    "    for optim in optimizers:\n",
    "        for i in range(5):\n",
    "            x0 = problem.initial_solution_proposal(i)\n",
    "            \n",
    "            if optim is str:\n",
    "                sol = minimize(problem, x0, method=optim)\n",
    "                func_evals.append(pd.DataFrame({'fid': fid, 'dim': dim, 'iid': iid, 'optim': optim, **dict(enumerate(x0)),'fun': sol.fun, 'nfev': sol.nfev, 'status': sol.status}, index = [0]))\n",
    "            elif optim is cma.CMAEvolutionStrategy:\n",
    "                x, es = cma.fmin2(problem, x0, 0.5)\n",
    "                sol = es.result._asdict()\n",
    "                func_evals.append(pd.DataFrame({'fid': fid, 'dim': dim, 'iid': iid, 'optim': 'CMA-ES', **dict(enumerate(x0)),'fun': sol['fbest'], 'nfev': sol['evaluations']}, index = [0]))\n",
    "func_evals = pd.concat(features).reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c716a19",
   "metadata": {},
   "outputs": [],
   "source": [
    "func_evals.columns = func_evals.columns.astype(str)\n",
    "func_evals.to_parquet('func_evals.gzip', compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcf1a5b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "func_evals = pd.read_parquet('func_evals.gzip')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1da4fec3",
   "metadata": {},
   "source": [
    "Read in the benchmark and find the optimal minimizer within an error margin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21d5d550",
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmark = pd.read_csv('imputed_relERT_costs_50d.csv').drop(['repetition'], axis=1).set_index(['dim', 'fid'])\n",
    "deviation = 0.01\n",
    "mins = benchmark.min(axis=1) * (1+deviation)\n",
    "#benchmark = benchmark.le(mins, axis='index').melt(value_vars=benchmark.columns, var_name='optimizer', ignore_index=False)\n",
    "benchmark = benchmark[benchmark.le(mins, axis='index')].melt(value_vars=benchmark.columns, var_name='optimizer', value_name='niter', ignore_index=False).dropna().sort_index()\n",
    "cat_mapping = benchmark.optimizer.astype('category').cat.categories.to_list()\n",
    "#cat_mapping = dict(zip(range(len(cat_mapping)), cat_mapping))\n",
    "benchmark.optimizer = benchmark.optimizer.astype('category').cat.codes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f49d7a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import HistGradientBoostingClassifier, GradientBoostingClassifier\n",
    "\n",
    "\n",
    "infeatures_fix = ['ic.h_max', 'ic.eps_s', 'ic.eps_max', 'ic.eps_ratio', 'ic.m0',\n",
    "       'ela_meta.lin_simple.adj_r2', 'ela_meta.lin_simple.intercept',\n",
    "       'ela_meta.lin_simple.coef.min', 'ela_meta.lin_simple.coef.max',\n",
    "       'ela_meta.lin_simple.coef.max_by_min',\n",
    "       'ela_meta.lin_w_interact.adj_r2', 'ela_meta.quad_simple.adj_r2',\n",
    "       'ela_meta.quad_simple.cond', 'ela_meta.quad_w_interact.adj_r2',\n",
    "       'ela_distr.skewness', 'ela_distr.kurtosis',\n",
    "       'ela_distr.number_of_peaks', 'nbc.nn_nb.sd_ratio',\n",
    "       'nbc.nn_nb.mean_ratio', 'nbc.nn_nb.cor',\n",
    "       'nbc.dist_ratio.coeff_var', 'nbc.nb_fitness.cor',\n",
    "       'disp.ratio_mean_25', 'disp.ratio_median_25', 'disp.diff_mean_25',\n",
    "       'disp.diff_median_25']\n",
    "\n",
    "levels = features.columns[features.columns.str.contains('ela_level')].to_list()\n",
    "pca = features.columns[features.columns.str.contains('pca')].to_list()\n",
    "\n",
    "clf = GradientBoostingClassifier()\n",
    "_slice = features.loc[features.dim == 2,:].dropna(axis=1)\n",
    "_slice = _slice.loc[:,~_slice.columns.str.contains('costs_runtime')]\n",
    "X = _slice.drop(['fid', 'dim', 'iid', 'sample_coefficient', 'n'] + levels +pca, axis=1, errors='ignore').replace([np.inf], 99999999)#.to_numpy()\n",
    "X = _slice.loc[:,infeatures_fix].replace([np.inf], 99999999)\n",
    "y = _slice.loc[:,'fid'].to_numpy()-1\n",
    "clf = clf.fit(X,y)\n",
    "\n",
    "##Eval\n",
    "clf_test = GradientBoostingClassifier()\n",
    "_slice = features_test.loc[features_test.dim == 2,:].dropna(axis=1)\n",
    "_slice = _slice.loc[:,~_slice.columns.str.contains('costs_runtime')]\n",
    "#levels = _slice.columns[_slice.columns.str.contains('ela_level')].to_list()\n",
    "#X = _slice.drop(['fid', 'dim', 'iid', 'sample_coefficient', 'n'] + levels +pca, axis=1, errors='ignore').replace([np.inf], 99999999)#.to_numpy()\n",
    "X = _slice.loc[:,infeatures_fix].replace([np.inf], 99999999)\n",
    "y = _slice.loc[:,'fid'].to_numpy()-1\n",
    "clf_test = clf_test.fit(X,y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d65ac22c",
   "metadata": {},
   "source": [
    "Set up RL Agent with custom feature exctractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "052a26b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "from gym import spaces\n",
    "from numpy.random import default_rng\n",
    "from stable_baselines3 import A2C, DQN\n",
    "from stable_baselines3.common.callbacks import EvalCallback\n",
    "from stable_baselines3.common.vec_env import SubprocVecEnv, VecNormalize, DummyVecEnv, VecCheckNan\n",
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "from stable_baselines3.common.utils import set_random_seed\n",
    "\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "import random\n",
    "\n",
    "from itertools import permutations\n",
    "from stable_baselines3.common.torch_layers import BaseFeaturesExtractor\n",
    "\n",
    "\n",
    "class ClassifierEnv(gym.Env):\n",
    "    \"\"\"Classifier Environment for ELA based AAS.\"\"\"\n",
    "\n",
    "    metadata = {\"render_modes\": [\"human\"], \"render_fps\": 30}\n",
    "\n",
    "    def __init__(self, classifier, truth, used_cols, fid='1-24', iid='1-5', dim=2, problem='bbob'):\n",
    "        super().__init__()\n",
    "        # Define action and observation space\n",
    "        # They must be gym.spaces objects\n",
    "        # Example when using discrete actions:\n",
    "        #self.problem_def = (problem, f\"instances:{iid}\", f\"function_indices:{fid} dimensions:{dim}\")\n",
    "        \n",
    "        self.suite = None# cocoex.Suite(problem, problem_select)\n",
    "        self.classifier = classifier\n",
    "        self.dim = dim\n",
    "        self.truth = truth\n",
    "        self.fid = fid\n",
    "        self.iid = iid\n",
    "        self.rng = default_rng()\n",
    "        self.used_cols = used_cols\n",
    "        self.random = True\n",
    "        \n",
    "        self.action_space = spaces.Discrete(2)\n",
    "        # Example for using image as input (channel-first; channel-last also works):\n",
    "        self.observation_space = spaces.Box(-np.inf, np.inf, shape=(1,len(used_cols)), dtype=np.float32)\n",
    "    \n",
    "    @staticmethod\n",
    "    def sigmoid(x):\n",
    "        return 1/(1+math.exp(-0.1*x))\n",
    "    \n",
    "    @staticmethod\n",
    "    def softplus(x):\n",
    "        return math.ln(1.0+math.exp(x))-1.0\n",
    "    \n",
    "    @staticmethod\n",
    "    def elu(x, alpha=1.0):\n",
    "        return x if x>0.0 else alpha*(math.exp(x)-1.0)\n",
    "    \n",
    "    def step(self, action):\n",
    "        if action == 0:\n",
    "            #X = create_initial_sample(self.dim, lower_bound = -5, upper_bound = 5, n=10, sample_type='random')\n",
    "            cols = [f\"x{i}\" for i in range(self.dim)]\n",
    "            X = pd.DataFrame(self.rng.random((10, self.dim))*10-5, columns=cols)\n",
    "            self.X = pd.concat([self.X, X], ignore_index=True)\n",
    "\n",
    "            observation = self.calc_ela(self.X)\n",
    "            if np.isnan(observation).any():\n",
    "                raise ValueError(f\"Nan err with {self.X}\")\n",
    "            reward = -1.0\n",
    "            done = False\n",
    "        elif action == 1:\n",
    "            #problem ready for AAS\n",
    "            observation = self.calc_ela(self.X)\n",
    "            #print(observation)\n",
    "            predict = self.classifier.predict(observation)[0]\n",
    "            fid = self.problem.id_function\n",
    "            dim = self.problem.dimension\n",
    "            mask = self.truth.loc[(dim,fid),'optimizer'] == predict\n",
    "            \n",
    "            if mask.any():\n",
    "                #print(self.truth.loc[(dim,fid),:])\n",
    "                niter = self.truth.loc[(dim,fid),'niter'][mask][0] #.values[0]\n",
    "                reward = self.elu(niter-self.X.shape[0])\n",
    "            else:\n",
    "                niter = self.truth.loc[(dim,fid),'niter'].min()\n",
    "                reward = -self.elu(niter-self.X.shape[0]) - 2\n",
    "            \n",
    "            done = True\n",
    "            \n",
    "            \n",
    "        else:\n",
    "            raise ValueError(\n",
    "                f\"Received invalid action={action} which is not part of the action space\"\n",
    "            )\n",
    "            \n",
    "        truncated = False\n",
    "        info = {}\n",
    "        \n",
    "        return observation, reward, done, info\n",
    "    \n",
    "        \n",
    "    \n",
    "    def calc_ela(self, X):\n",
    "        \n",
    "        y = X.apply(lambda x: self.problem(x), axis = 1)\n",
    "        \n",
    "        ela_meta = calculate_ela_meta(X, y)\n",
    "        ela_distr = calculate_ela_distribution(X, y)\n",
    "        fast_k = max(math.ceil(0.05 * X.shape[0]),2)\n",
    "        try:\n",
    "            nbc = calculate_nbc(X, y, fast_k=fast_k)\n",
    "        except IndexError as e:\n",
    "            print(X)\n",
    "            print(y)\n",
    "            raise e\n",
    "        disp = calculate_dispersion(X, y)\n",
    "        #try:\n",
    "        #    ic = calculate_information_content(X, y, seed = 100)\n",
    "        #except KeyError as e:\n",
    "        #    assert (X.index==y.index).all()\n",
    "        #    print(X)\n",
    "        #    print(y)\n",
    "        #    raise e\n",
    "        ##pca = calculate_pca(X, y)\n",
    "        #try:\n",
    "        #    level = calculate_ela_level(X, y)\n",
    "        #except Exception:\n",
    "        #    level = {}\n",
    "        data = {**ic, **ela_meta, **ela_distr, **nbc, **disp, } #**pca\n",
    "        del data['ela_meta.costs_runtime']\n",
    "        #del data['pca.costs_runtime']\n",
    "        del data['nbc.costs_runtime']\n",
    "        del data['disp.costs_runtime']\n",
    "        del data['ic.costs_runtime']\n",
    "        del data['ela_distr.costs_runtime']\n",
    "        #del data['limo.costs_runtime']\n",
    "        #del data['cm_angle.costs_runtime']\n",
    "        #del data['cm_conv.costs_runtime']\n",
    "        #del data['cm_grad.costs_runtime']\n",
    "        #del data['ela_conv.costs_runtime']\n",
    "        #del data['ela_level.costs_runtime']\n",
    "        #del data['ela_curv.costs_runtime']\n",
    "        #del data['ela_local.costs_runtime']\n",
    "        #data = {k,v for k,v in data.items() if not \"costs_runtime\" in k}\n",
    "        \n",
    "        data = {k:v for k,v in data.items() if k in self.used_cols}\n",
    "        result = np.array(list(data.values()), dtype=np.float32).reshape(1, -1)\n",
    "        result[np.isnan(result)] = 0#-(2**32)#-np.inf\n",
    "        print(result)\n",
    "        print(result.shape)\n",
    "        return result#torch.nan_to_num(result, nan=-(2.0**32))\n",
    "        #return {**ic, **ela_meta, **ela_distr, **nbc, **disp, **pca}#**level\n",
    "    \n",
    "    def next_problem(self, options=None):\n",
    "        self.X = None\n",
    "        if self.random:\n",
    "            fid = random.choice(self.funcs)\n",
    "            self.problem = self.suite.get_problem(fid)\n",
    "        else:\n",
    "            self.problem = next(self.problem_selector)\n",
    "        self.X = create_initial_sample(self.dim, lower_bound = -5, upper_bound = 5, n=10, sample_type='lhs')\n",
    "\n",
    "        observation = self.calc_ela(self.X)\n",
    "        return observation#, info\n",
    "    \n",
    "    def reset(self, fid='1-24', iid='1-5', seed=0, n_samples=10, options=None):\n",
    "        \n",
    "        #problem_def = ('bbob', f\"instances:{iid}\", f\"function_indices:{fid} dimensions:{dim}\")\n",
    "        self.suite = cocoex.Suite('bbob', f\"instances:{iid}\", f\"function_indices:{fid} dimensions:{self.dim}\")\n",
    "        self.problem_selector = iter(self.suite)\n",
    "        self.funcs = self.suite.ids()\n",
    "        \n",
    "        return self.next_problem()\n",
    "    \n",
    "    def render(self):\n",
    "        pass\n",
    "\n",
    "    def close(self):\n",
    "        pass\n",
    "    \n",
    "    \n",
    "class SimpelConvNet(BaseFeaturesExtractor):\n",
    "    \"\"\"\n",
    "    :param observation_space: (gym.Space)\n",
    "    :param features_dim: (int) Number of features extracted.\n",
    "        This corresponds to the number of unit for the last layer.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, observation_space: spaces.Box, features_dim: int = 26):\n",
    "        super().__init__(observation_space, features_dim)\n",
    "        #NxCxL batchXchannelXfeatures\n",
    "        n_channels = observation_space.shape[0]\n",
    "        self.cnn = nn.Sequential(\n",
    "            nn.Conv1d(n_channels, 16, kernel_size=4),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(16, 32, kernel_size=4),#, dilation=3\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(32, 64, kernel_size=4),\n",
    "            nn.ReLU(),\n",
    "            nn.Flatten(),\n",
    "        )\n",
    "        with torch.no_grad():\n",
    "            #print(observation_space.sample()[:,None].shape)\n",
    "            n_flatten = self.cnn(\n",
    "                torch.as_tensor(observation_space.sample()[:,None]).float()\n",
    "            ).shape[1]\n",
    "        print(n_flatten)\n",
    "        self.linear = nn.Sequential(nn.Linear(n_flatten, features_dim), nn.ReLU())\n",
    "        \n",
    "    def forward(self, observations: torch.Tensor) -> torch.Tensor:\n",
    "        return self.linear(self.cnn(observations))\n",
    "    \n",
    "class SkipNetwork(BaseFeaturesExtractor):\n",
    "    \"\"\"\n",
    "    :param observation_space: (gym.Space)\n",
    "    :param features_dim: (int) Number of features extracted.\n",
    "        This corresponds to the number of unit for the last layer.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, observation_space: spaces.Box, features_dim: int = 26):\n",
    "        super().__init__(observation_space, features_dim)\n",
    "        #NxCxL batchXchannelXfeatures\n",
    "        n_channels = observation_space.shape[0]\n",
    "        self.cnn = nn.Sequential(\n",
    "            nn.Conv1d(n_channels, 16, kernel_size=4),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(16, 32, kernel_size=4, dilation=3),\n",
    "            nn.ReLU(),\n",
    "            nn.Flatten(),\n",
    "        )\n",
    "        self.conv1 = nn.Conv1d(n_channels, 16, kernel_size=4)\n",
    "        self.conv2 = nn.Conv1d(16, 32, kernel_size=4, dilation=3)\n",
    "        self.flatten = nn.Flatten()\n",
    "        with torch.no_grad():\n",
    "            #print(observation_space.sample()[:,None].shape)\n",
    "            n_flatten = self.flatten(self.conv2(self.conv1(\n",
    "                torch.as_tensor(observation_space.sample()[:,None]).float()\n",
    "            ))).shape[1] + features_dim\n",
    "        print(f\"feat:{features_dim}\")\n",
    "        self.linear = nn.Sequential(nn.Linear(n_flatten, features_dim), nn.ReLU())\n",
    "        \n",
    "    def forward(self, observations: torch.Tensor) -> torch.Tensor:\n",
    "        #out = observations.copy()\n",
    "        x = self.conv1(observations)\n",
    "        x = nn.ReLU()(x)\n",
    "        x = self.conv2(x)\n",
    "        x = nn.ReLU()(x)\n",
    "        x = self.flatten(x)\n",
    "        x = torch.cat((x, self.flatten(observations)), 1)\n",
    "        \n",
    "        return self.linear(x)\n",
    "    \n",
    "from stable_baselines3.common.env_checker import check_env\n",
    "\n",
    "def make_env(rank, seed=0):\n",
    "    def _init():\n",
    "        env = ClassifierEnv(clf, benchmark[~benchmark.index.duplicated(keep='first')], infeatures_fix, dim=rank+2)\n",
    "        env.seed(rank)\n",
    "        return env\n",
    "    set_random_seed(seed)\n",
    "    return _init\n",
    "\n",
    "#env = ClassifierEnv(clf, benchmark[~benchmark.index.duplicated(keep='first')], infeatures_fix)\n",
    "\n",
    "num_cpu = 1\n",
    "#env = make_env(1)()\n",
    "env = SubprocVecEnv([make_env(i) for i in range(1)])\n",
    "env = VecNormalize(env, training=True, norm_obs=True, norm_reward=True)\n",
    "#env = VecCheckNan(env, raise_exception=True)\n",
    "obs = env.reset()\n",
    "#model = A2C(\"MlpPolicy\", env, learning_rate=0.0007, verbose=1, tensorboard_log=\"./dqn_AAS_tensorboard/\")\n",
    "#policy_kwargs = dict(net_arch=dict(pi= [16,16], vf=[16,16]))\n",
    "policy_kwargs = dict(\n",
    "    features_extractor_class=SimpelConvNet,\n",
    "    features_extractor_kwargs=dict(features_dim=obs.shape[2])\n",
    ")#dict(net_arch=[64,64,16])\n",
    "#print(obs.shape)\n",
    "model = A2C(\"MlpPolicy\", env, policy_kwargs=policy_kwargs, tensorboard_log=\"./dqn_AAS_tensorboard/\", verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "907ce70c",
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "\n",
    "def make_evalenv(rank, seed=0):\n",
    "    def _init():\n",
    "        env = ClassifierEnv(clf_test, benchmark[~benchmark.index.duplicated(keep='first')], infeatures_fix, dim=rank+2)\n",
    "        env.seed(rank)\n",
    "        return env\n",
    "    set_random_seed(seed)\n",
    "    return _init\n",
    "\n",
    "\n",
    "eval_env = DummyVecEnv([make_evalenv(i, seed=3) for i in range(1)])\n",
    "#eval_env = DummyVecEnv(eval_env)\n",
    "eval_env = VecNormalize(eval_env, training=True, norm_obs=True, norm_reward=True)\n",
    "eval_callback = EvalCallback(eval_env, log_path=\"./logs/\", eval_freq=50,\n",
    "                            deterministic=True, render=False)\n",
    "\n",
    "model.learn(total_timesteps=10_000)#, callback=eval_callback)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80b5d3df",
   "metadata": {},
   "outputs": [],
   "source": [
    "env.step([0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afdca2c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "infeatures_fix[12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16369f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8576d1a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "obs = env.reset('1-24', '1-5')\n",
    "for i in range(100):\n",
    "    action, _state = model.predict(obs, deterministic=True)\n",
    "    obs, reward, done, info = env.step(action)\n",
    "    if done:\n",
    "        print(f\"Done in {i}\")\n",
    "        break\n",
    "        \n",
    "        obs = env.next_problem()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b7ff20a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75a0ebb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "def func(x):\n",
    "    y = np.where(x <3, np.log(1+np.exp(x)), 0)\n",
    "    #\n",
    "    mask = np.insert(np.diff(y),0,0)\n",
    "    y[mask < 0.0] = np.nan\n",
    "    return y\n",
    "def func2(x):\n",
    "    y = np.where(x<3, np.where(x>0, x, np.exp(x)-1), -x)\n",
    "    #y = #np.where(x>3, np.where(x>0, -x, np.exp(x)-1), np.exp(x)-1)\n",
    "    mask = np.insert(np.diff(y),0,0)\n",
    "    print(mask)\n",
    "    y[(mask < -1.0) ] = np.nan\n",
    "    return y\n",
    "x = np.arange(-3.0, 5.0, 0.1)\n",
    "plt.figure(figsize=(2,5))\n",
    "plt.plot(x, func2(x), 'k')\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f403156b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('imputed_relERT_costs_50d.csv').drop(['repetition'],axis=1)\n",
    "#df['min']= df.min(axis=1)\n",
    "df = pd.melt(df, id_vars=['dim','fid'], value_vars=df.columns.drop(['dim','fid']))\n",
    "\n",
    "sns.set_theme(style=\"ticks\")\n",
    "f, ax = plt.subplots(figsize=(7, 6))\n",
    "ax.set_yscale(\"log\")\n",
    "sns.boxplot(data=df[(df.fid<25)&(df.dim==10)],\n",
    "            y='value',\n",
    "            x='fid',\n",
    "            width=.6,\n",
    "            whis=[0, 100]\n",
    "           )\n",
    "ax.xaxis.grid(True)\n",
    "ax.set(ylabel=\"\")\n",
    "sns.despine(trim=True, left=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22f20e20",
   "metadata": {},
   "source": [
    "Architecture evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b734bdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "from gymnasium import spaces\n",
    "\n",
    "from stable_baselines3.common.torch_layers import BaseFeaturesExtractor\n",
    "\n",
    "m = nn.Conv1d(1, 16, 4)\n",
    "n = nn.Conv1d(1, 16, 4, dilation=3)\n",
    "infeatures_fix = ['ic.h_max', 'ic.eps_s', 'ic.eps_max', 'ic.eps_ratio', 'ic.m0',\n",
    "       'ela_meta.lin_simple.adj_r2', 'ela_meta.lin_simple.intercept',\n",
    "       'ela_meta.lin_simple.coef.min', 'ela_meta.lin_simple.coef.max',\n",
    "       'ela_meta.lin_simple.coef.max_by_min',\n",
    "       'ela_meta.lin_w_interact.adj_r2', 'ela_meta.quad_simple.adj_r2',\n",
    "       'ela_meta.quad_simple.cond', 'ela_meta.quad_w_interact.adj_r2',\n",
    "       'ela_distr.skewness', 'ela_distr.kurtosis',\n",
    "       'ela_distr.number_of_peaks', 'nbc.nn_nb.sd_ratio',\n",
    "       'nbc.nn_nb.mean_ratio', 'nbc.nn_nb.cor',\n",
    "       'nbc.dist_ratio.coeff_var', 'nbc.nb_fitness.cor',\n",
    "       'disp.ratio_mean_25', 'disp.ratio_median_25', 'disp.diff_mean_25',\n",
    "       'disp.diff_median_25']\n",
    "data = torch.tensor(features_test.loc[:,infeatures_fix].values, dtype=torch.float).unsqueeze(1)\n",
    "output = n(data)\n",
    "output.shape\n",
    "class SimpelConvNet(BaseFeaturesExtractor):\n",
    "    \"\"\"\n",
    "    :param observation_space: (gym.Space)\n",
    "    :param features_dim: (int) Number of features extracted.\n",
    "        This corresponds to the number of unit for the last layer.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, observation_space: space.Box, features_dim: int = 26):\n",
    "        super().__init__(observation_space, features_dim)\n",
    "        #NxCxL batchXchannelXfeatures\n",
    "        n_channels = observation_space.shape[1]\n",
    "        self.cnn = nn.Sequential(\n",
    "            nn.Conv1d(n_channels, 16, 4, kernel_size=3),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(n_channels, 16, 4, dilation=3, kernel_size=3),\n",
    "            nn.ReLU(),\n",
    "            nn.Flatten(),\n",
    "        )\n",
    "        with torch.no_grad():\n",
    "            n_flatten = self.cnn(\n",
    "                torch.as_tensor(observation_space.sample()[None]).float()\n",
    "            ).shape[1]\n",
    "        self.linear = nn.Sequential(nn.Linear(n_flatten, features_dim), nn.ReLU())\n",
    "        \n",
    "    def forward(self, observations: torch.Tensor) -> torch.Tensor:\n",
    "        return self.linear(self.cnn(observations))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "530e2e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5503992",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_test.loc[features_test.dim==3,infeatures_fix]['disp.diff_median_25'].plot(kind='kde')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc2be499",
   "metadata": {},
   "source": [
    "\\[-1,1\\]:\n",
    "- ela_meta.lin_simple.adj_r2\n",
    "- ela_meta.lin_w_interact.adj_r2\n",
    "- ela_meta.quad_simple.adj_r2\n",
    "- ela_meta.quad_w_interact.adj_r2\n",
    "- ela_distr.number_of_peaks\n",
    "- disp.ratio_mean_25\n",
    "- disp.ratio_median_25\n",
    "- disp.diff_mean_25\n",
    "- disp.diff_median_25\n",
    "\n",
    "additionally clip: 75%\n",
    "- ic.eps_max\n",
    "- ela_meta.lin_simple.intercept\n",
    "- ela_meta.lin_simple.coef.min\n",
    "- ela_meta.lin_simple.coef.max\n",
    "- ela_meta.lin_simple.coef.max_by_min\n",
    "- ela_meta.quad_simple.cond\n",
    "\n",
    "norm:\n",
    "- ela_distr.skewness\n",
    "- ela_distr.kurtosis\n",
    "- nbc.nn_nb.sd_ratio\n",
    "- nbc.nn_nb.mean_ratio\n",
    "- nbc.nn_nb.cor\n",
    "- nbc.dist_ratio.coeff_var\n",
    "- nbc.nb_fitness.cor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19526b45",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
